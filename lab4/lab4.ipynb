{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171d1922",
   "metadata": {},
   "source": [
    "# Text similarity methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d659f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import fclusterdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a0df2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95eac6c",
   "metadata": {},
   "source": [
    "## 1. Zaimplementuj przynajmniej 3 \"metryki\" spośród wymienionych: cosinusowa, LCS, DICE, euklidesowa, Levenshteina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82ed41",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}= \\frac{\\sum\\limits_{i=1}^{n} A_i B_i}{\\sqrt{\\sum\\limits_{i=1}^{n} A_i^2} \\sqrt{\\sum\\limits_{i=1}^{n} B_i^2}}\n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &\\mathbf{A}\\text{ and }\\mathbf{B} \\text{ are the two vectors being compared}\\\\\n",
    "    &n \\text{ is the dimensionality of the vectors}\\\\\n",
    "    &\\theta \\text{ represents the angle between two vectors } \\mathbf{A} \\text{ and } \\mathbf{B} \\text{ in a high-dimensional space}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The dot product of $\\mathbf{A}$ and $\\mathbf{B}$ is divided by the product of their Euclidean lengths to normalize the result to a range of [-1, 1]. A value of 1 indicates that the two vectors are identical, while a value of -1 indicates that they are completely dissimilar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1fa4263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector_a, vector_b) -> float:\n",
    "    if np.linalg.norm(vector_a) == 0 or np.linalg.norm(vector_b) == 0:\n",
    "        return 2\n",
    "    return -(np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b888d",
   "metadata": {},
   "source": [
    "### Dice coefficient / Sørensen-Dice Index\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\text{Dice}(A, B) = \\frac{2 |A \\cap B|}{|A| + |B|} \n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &A \\text{ and } B \\text{ represent the two sets being compared} \\\\\n",
    "    &|A| \\text{ and } |B| \\text{ represent the cardinality (number of elements) of the sets} \\\\\n",
    "    &\\text{and } |A \\cap B| \\text{ represents the size of the intersection of the two sets}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d87bfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(vector_a, vector_b) -> float:\n",
    "    x = np.count_nonzero(vector_a)\n",
    "    y = np.count_nonzero(vector_b)\n",
    "    if  x+y == 0:\n",
    "        return 2\n",
    "    return -((2 * np.count_nonzero(vector_a * vector_b)) / (x+y)) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997da4a2",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}\n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &d(x,y) \\text{ is the Euclidean distance} \\\\\n",
    "    &x_i, y_i \\text{ are the values of the i-th dimension of vectors } x \\text{ and } y \\\\\n",
    "    &n \\text{ is the number of dimensions in the vectors}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a96145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance( vector_a, vector_b) -> float:\n",
    "    return np.linalg.norm(vector_a - vector_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddc2b1",
   "metadata": {},
   "source": [
    "## 2. Zaimplementuj przynajmniej 1 sposób oceny jakości klasteryzacji (np. indeks Daviesa-Bouldina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4948bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(indexes, vectors):\n",
    "    centroid = sum(vectors[indexes])\n",
    "    centroid = centroid / len(indexes)\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "0cc7d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_distance(centroid, vectors, indexes, metric):\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(indexes)):\n",
    "        total += metric(centroid, vectors[indexes[i]])\n",
    "\n",
    "    return total / len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "72ce61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_index(vectors, clusters, metric):\n",
    "    unique_clusters = set(clusters)\n",
    "    \n",
    "    centroids = {}\n",
    "    for cluster_idx in unique_clusters:\n",
    "        indexes = np.where(clusters == cluster_idx)[0]\n",
    "        centroids[cluster_idx] = get_centroid(indexes, vectors)\n",
    "    \n",
    "    avg_distances = [0]\n",
    "    for cluster_idx in unique_clusters:\n",
    "        indexes = np.where(clusters == cluster_idx)[0]\n",
    "        avg_distances.append(get_avg_distance(centroids[cluster_idx], vectors, indexes, metric))\n",
    "    \n",
    "    seperations = [[0 for _ in range(len(unique_clusters) + 1)] for _ in range(len(unique_clusters) + 1)]\n",
    "    for i in unique_clusters:\n",
    "        for j in unique_clusters:\n",
    "            seperations[i][j] = metric(centroids[i], centroids[j])\n",
    "    \n",
    "    results = [[0 for _ in range(len(unique_clusters) + 1)] for _ in range(len(unique_clusters) + 1)]\n",
    "    for i in unique_clusters:\n",
    "        for j in unique_clusters:\n",
    "            if i != j:\n",
    "                results[i][j] = (avg_distances[i] + avg_distances[j]) / seperations[i][j]\n",
    "    \n",
    "    Ds = [0 for _ in range(len(unique_clusters) + 1)]\n",
    "    for i in unique_clusters:\n",
    "        result1 = results[i][:i]\n",
    "        result2 = results[i][i+1:]\n",
    "        if len(result1):\n",
    "            Ds[i] = max(Ds[i], max(result1))\n",
    "        if len(result2):\n",
    "            Ds[i] = max(Ds[i], max(result2))\n",
    "    \n",
    "    return sum(Ds) / len(Ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293c529",
   "metadata": {},
   "source": [
    "## 3. Stwórz stoplistę najczęściej występujących słów i zastosuj ją jako pre-processing dla nazw. Algorytmy klasteryzacji powinny działać na dwóch wariantach: z pre-processingiem i bez pre-processingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c26834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Words_Bagging:\n",
    "    def __init__(self, texts: list[str]) -> None:\n",
    "        self.texts_without_noises = self.remove_noises(texts)\n",
    "        self.words_bag = self.find_words_bag()\n",
    "        \n",
    "    def remove_noises(self, texts) -> None:\n",
    "        texts_without_noises = []\n",
    "        for text in texts:\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^\\w\\s]', '' , text)\n",
    "            texts_without_noises.append(text)    \n",
    "        \n",
    "        return texts_without_noises\n",
    "    \n",
    "    def find_words_bag(self) -> dict[str, int]:\n",
    "        words_bag = {}\n",
    "        idx = 0\n",
    "\n",
    "        for text in self.texts_without_noises:\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                if word not in words_bag:\n",
    "                    words_bag[word] = idx\n",
    "                    idx += 1\n",
    "\n",
    "        return words_bag\n",
    "    \n",
    "    def get_words_bag(self) -> dict[str, int]:\n",
    "        vectors = self.texts_to_vectors(self.words_bag)\n",
    "        return self.words_bag, vectors\n",
    "    \n",
    "    def texts_to_vectors(self, words_bag: dict[str, int]) -> list[list[int]]:\n",
    "        freq_vecs = []\n",
    "\n",
    "        for text in self.texts_without_noises:\n",
    "            vector = np.zeros(len(words_bag))\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                if word in words_bag:\n",
    "                    idx = words_bag[word]\n",
    "                    vector[idx] += 1\n",
    "            \n",
    "            freq_vecs.append(VectorText(text, vector))\n",
    "\n",
    "        return freq_vecs\n",
    "    \n",
    "    def get_preprocessed_words_bag(self, number_of_most_popular_words_to_remove: int = None) -> dict[str, int]:\n",
    "        if number_of_most_popular_words_to_remove is None:\n",
    "            number_of_most_popular_words_to_remove = len(self.words_bag) // 5\n",
    "            \n",
    "        preprocessed_words_bag = self.preprocess(number_of_most_popular_words_to_remove)\n",
    "        vectors = self.texts_to_vectors(preprocessed_words_bag)\n",
    "        return preprocessed_words_bag, vectors\n",
    "    \n",
    "    def preprocess(self, number_of_most_popular_words_to_remove: int) -> str:\n",
    "        stop_list = self.get_stop_list(number_of_most_popular_words_to_remove)\n",
    "        preprocessed_words_bag = self.words_bag.copy()\n",
    "        \n",
    "        for stop_word in stop_list:\n",
    "            preprocessed_words_bag.pop(stop_word)\n",
    "        \n",
    "        idx = 0\n",
    "        for key in preprocessed_words_bag.keys():\n",
    "            preprocessed_words_bag[key] = idx\n",
    "            idx += 1\n",
    "            \n",
    "        return preprocessed_words_bag\n",
    "    \n",
    "    def get_stop_list(self, size: int) -> list[str]:\n",
    "        stop_list = []\n",
    "        \n",
    "        words_frequency = self.get_words_frequency()    \n",
    "        words_with_frequencies = [(word, words_frequency[index]) for (word, index) in self.words_bag.items()]\n",
    "        sorted_words_with_frequencies = sorted(words_with_frequencies, key=lambda x: -x[1])\n",
    "        \n",
    "        stop_list = [sorted_words_with_frequencies[i][0] for i in range(size)]\n",
    "\n",
    "        return stop_list\n",
    "    \n",
    "    def get_words_frequency(self) -> list[int]:\n",
    "        words_frequency = [0 for _ in range(len(self.words_bag))]\n",
    "\n",
    "        for text in self.texts_without_noises:\n",
    "            available = [True for _ in range(len(self.words_bag))]\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                idx = self.words_bag[word]\n",
    "                if available[idx]:\n",
    "                    words_frequency[idx] += 1\n",
    "                    available[idx] = False\n",
    "\n",
    "        return words_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7f631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorText:\n",
    "    def __init__(self, text, vector):\n",
    "        self.text = text\n",
    "        self.vector = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940818c",
   "metadata": {},
   "source": [
    "## 4. Wykonaj klasteryzację zawartości załączonego pliku (lines.txt) przy użyciu  metryk zaimplementowanych w pkt. 1. Każda linia to adres pocztowy firmy, różne sposoby zapisu tego samego adresu powinny się znaleźć w jednym klastrze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "64f8003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lines.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "lines = lines[:1000]\n",
    "WB = Words_Bagging(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813e6c2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "1e546f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bag_without_preprocessing, vectors_without_preprocessing = WB.get_words_bag()\n",
    "vectors1 = np.array([vector.vector for vector in vectors_without_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "457ecc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cosine_similarity_without_preprocessing = fclusterdata(vectors1, t=5000, criterion=\"maxclust\",metric=cosine_similarity)\n",
    "result_cosine_similarity_without_preprocessing = np.array(result_cosine_similarity_without_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "272768e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dice_coefficient_without_preprocessing = fclusterdata(vectors1, t=5000, criterion=\"maxclust\",metric=dice_coefficient)\n",
    "result_dice_coefficient_without_preprocessing = np.array(result_dice_coefficient_without_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "9de492ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_euclidean_distance_without_preprocessing = fclusterdata(vectors1, t=5000, criterion=\"maxclust\",metric=euclidean_distance)\n",
    "result_euclidean_distance_without_preprocessing = np.array(result_euclidean_distance_without_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388cd5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ea0a033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bag_with_preprocessing, vectors_with_preprocessing = WB.get_preprocessed_words_bag(400)\n",
    "vectors2 = np.array([vector.vector for vector in vectors_with_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2527f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cosine_similarity_with_preprocessing = fclusterdata(vectors2, t=5000, criterion=\"maxclust\",metric=cosine_similarity)\n",
    "result_cosine_similarity_with_preprocessing = np.array(result_cosine_similarity_with_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "bfdcd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dice_coefficient_with_preprocessing = fclusterdata(vectors2, t=5000, criterion=\"maxclust\",metric=dice_coefficient)\n",
    "result_dice_coefficient_with_preprocessing = np.array(result_dice_coefficient_with_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "7fc37ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_euclidean_distance_with_preprocessing = fclusterdata(vectors2, t=5000, criterion=\"maxclust\",metric=euclidean_distance)\n",
    "result_euclidean_distance_with_preprocessing = np.array(result_euclidean_distance_with_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af075e0e",
   "metadata": {},
   "source": [
    "## 5. Porównaj jakość wyników sposobami zaimplementowanymi w pkt. 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e5a77",
   "metadata": {},
   "source": [
    "### Metryka - cosinus similarity bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "bf96100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4772602942089679"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors1, result_cosine_similarity_without_preprocessing, cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbe288",
   "metadata": {},
   "source": [
    "### Metryka - cosinus similarity ze stoplistą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "6f1fa587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584115819992787"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors2, result_cosine_similarity_with_preprocessing, cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc0a1df",
   "metadata": {},
   "source": [
    "### Metryka - dice coefficient bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "7c22c190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4354596505140353"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors1, result_dice_coefficient_without_preprocessing, dice_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828dbee",
   "metadata": {},
   "source": [
    "### Metryka - dice coefficient ze stoplistą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "8f3512c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5490550850985179"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors2, result_dice_coefficient_with_preprocessing, dice_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5acfd",
   "metadata": {},
   "source": [
    "### Metryka - euclidean distance bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "9788bc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors1, result_euclidean_distance_without_preprocessing, euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bb855",
   "metadata": {},
   "source": [
    "### Metryka - euclidean distance ze stoplistą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "25c07aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_index(vectors2, result_euclidean_distance_with_preprocessing, euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4f724",
   "metadata": {},
   "source": [
    "## 6. Czy masz jakiś pomysł na poprawę jakości klasteryzacji w tym zadaniu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa6e3c",
   "metadata": {},
   "source": [
    "1. Możnaby lepiej dobrać liczbę najpopularniejszych słów do usunięcia z tekstów, oraz usunąć rzadko pojawiające się słowa\n",
    "2. Lepsze dane - na danych które mieliśmy nasze metryki mogły pomijać rezultaty w których spacje są wstawione w środku zdań, możnaby zastosować dodatkowy preprocessing.\n",
    "3. Uwzględnienie tego by wyrazy które się w sobie zawierają były bliżej lub nawet były traktowane jako to samo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b309eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (geometric algorithms)",
   "language": "python",
   "name": "pycharm-94575330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
